[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISYE 6420 - BUGS to Stan",
    "section": "",
    "text": "Introduction\nThis repository contains R translations of examples from Georgia Tech’s ISYE 6420: Bayesian Statistics, created by Professor Brani Vidakovic and currently taught by Professor Roshan Joseph and head TA Greg Schreiter. It also has additional notes on each lecture.\n\n\nWhy?\nWhen I was taking this course the only option for Mac users was to either use a virtual machine to run WinBUGS/OpenBUGS. During the semester I was taking this, Aaron Reding was creating an alternate using Python and PyMC (see here), but I found that PyMC had too many extra steps and was still fairly buggy.\nAfter quite a bit of research, I stumbled across Stan. The benefits that Stan provides over PyMC is that it can be run using Python (PyStan or CmdStanPy) or R (CmdStanR or RStan) or MATLAB, most of the models would also look similar to WinBUGS/OpenBUGS and finally the documentation for Stan is excellent.\nWhen I became a TA for this course I noticed that not a lot of people were using Stan, so I wanted to give the students an alternative to running Markov Chain Monte Carlo for Bayesian statistics.\n\n\nSite Structure\nThis site was built with Quarto Book and is made up of a combination of Stan files and Quarto Document (which is similar to RMarkdown files). You can view the entire repository on GitHub.\nAll pages match a corresponding lecture on Canvas, except when there are more pages than lectures in a unit. in which case the additional pages will be at the end of the unit. For example there are only eight lectures in Unit 3 on Canvas. The first eight pages here match the lecture numbers, while the ninth page has a supplementary problem and wasn’t part of the original lectures.\nAny necessary data will either have a download link or, if the data is compact enough, will be included in the code.\n\n\nPlans\nAs of Summer 2023, this is still a work in progress. I have been working through each unit trying to add the important information. Stan is heavily used from Unit 6 on, so that has been where my focus has been aligned."
  },
  {
    "objectID": "about-class.html#other-recommended-resources",
    "href": "about-class.html#other-recommended-resources",
    "title": "About this course and website",
    "section": "Other recommended resources",
    "text": "Other recommended resources\nThese are not required for the class, but they might be helpful. Prof. Vidakovic’s lectures often assume that the student has a certain amount of background knowledge, so if you feel lost or if you just want to dive deeper into the subject check them out.\n\nTextbooks and courses\nStatistical Rethinking by Richard McElreath is a great book for gaining intuition about Bayesian inference and modeling in general.\n\nmain site\nlecture videos\nR and Stan code examples.\n\nBayesian Data Analysis by Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin goes into more mathematical theory than Statistical Rethinking. I use it as a reference - not planning to try reading this one all the way through!\n\nmain site\npdf\n\n\n\nBlogs\n\nAndrew Gelman, author of Bayesian Data Analysis (above), has a blog: Statistical Modeling, Causal Inference, and Social Science.\nDan Simpson, one of the maintainers of the Stan PPL, has a blog called Un garçon pas comme les autres (Bayes) with opinionated and funny deep dives into various Bayesian topics. Warning: NSFW language.\nCount Bayesie: Probably a probability blog by Will Kurt.\nMichael Betancourt, another Stan developer, has a series of incredibly in-depth posts and notebooks on Bayesian modeling.\nPyMC developer Austin Rochford’s blog has a lot of good posts.\nAnother PyMC developer, Oriol Abril, posts some really helpful PyMC examples.\n\n\n\nPodcasts\n\nLearn Bayes Stats by Alex Andorra, one of the PyMC developers.\n\n\n\nOther\n\nStan User’s Guide\nAaron Reding’s PyMC"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Placeholder",
    "section": "",
    "text": "Warning\n\n\n\nI have not made it to this point, so this is currently just a placeholder. Please check back regularly as we are updating the files."
  },
  {
    "objectID": "unit6/stress_diet.html#problem-statement",
    "href": "unit6/stress_diet.html#problem-statement",
    "title": "Stress, Diet, and Plasma Acids",
    "section": "Problem Statement",
    "text": "Problem Statement\nIn the study Interrelationships Between Stress, Dietary Intake, and Plasma Ascorbic Acid During Pregnancy conducted at the Virginia Polytechnic Institute and State University, the plasma ascorbic acid levels of pregnant women were compared for smokers versus non-smokers. Thirty-two women in the last three months of pregnancy, free of major health disorders, and ranging in age from 15 to 32 years were selected for the study. Prior to the collection of 20 ml of blood, the participants were told to avoid breakfast, forego their vitamin supplements, and avoid foods high in ascorbic acid content. From the blood samples, the plasma ascorbic acid values of each subject were determined in milligrams per 100 milliliters.\n\nI start with the data pasted from stressacids.odc, then create one list for smokers and one for nonsmokers.\n\nplasma <- c(0.97, 0.72, 1.00, 0.81, 0.62, 1.32, 1.24, 0.99, 0.90, 0.74,\n          0.88, 0.94, 1.06, 0.86, 0.85, 0.58, 0.57, 0.64, 0.98, 1.09,\n          0.92, 0.78, 1.24, 1.18, 0.48, 0.71, 0.98, 0.68, 1.18, 1.36,\n          0.78, 1.64)\n\nsmo <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2)\n\nnonsmoker_index <- which(smo == 1)\nplasma_smokers <- plasma[-nonsmoker_index]\nplasma_nonsmokers <- plasma[nonsmoker_index]\n\n\nBUGS step function\nBUGS defines the step function like this:\n\\[\nstep(e) = \\left\\{\n\\begin{array}{rl}\n  1, &\\; e \\geq 0\\\\\n  0, &\\; \\text{otherwise}\n\\end{array}\\right.\n\\]\nStan follows what you would expect in a programming language. We implement this like:\ne >= 0 ? 1 : 0;\n\n\nHow do I track non-random variables in Stan?\nOne nice thing about BUGS is you can easily track both deterministic and non-deterministic variables while sampling. For Stan, you add the variable to the generated quantities block.\n\nmod <- cmdstan_model(stress_diet_stan)\n\n\n\nStress, Diet, and Plasma Acids Model\n\n\ndata {\n  int<lower=0> N_smoker;\n  int<lower=0> N_nonsmoker;\n  vector[N_smoker] plasma_smoker;\n  vector[N_nonsmoker] plasma_nonsmoker;\n}\n\nparameters {\n  real<lower=0> tau_nonsmoker;\n  real mu_nonsmoker;\n  real<lower=0> tau_smoker;\n  real mu_smoker;\n}\n\nmodel {\n  tau_nonsmoker ~ gamma(0.0001, 0.0001);\n  tau_smoker ~ gamma(0.0001, 0.0001);\n  mu_nonsmoker ~ normal(0, 100); // equivalent to BUGS tau = 0.0001\n  mu_smoker ~ normal(0, 100);\n  \n  plasma_smoker ~ normal(mu_smoker, 1 / sqrt(tau_smoker));\n  plasma_nonsmoker ~ normal(mu_nonsmoker, 1 / sqrt(tau_nonsmoker));\n}\n\ngenerated quantities {\n  real testmu;\n  real r;\n  \n  testmu = (mu_smoker >= mu_nonsmoker ? 1 : 0);\n  r = tau_nonsmoker / tau_smoker;\n}\n\n\n\n\nSampling\nLet us prepare the data to be passed into sample\n\ninput_data <- list(N_smoker=length(plasma_smokers), \n                   N_nonsmoker=length(nonsmoker_index),\n                   plasma_smoker=plasma_smokers,\n                   plasma_nonsmoker=plasma_nonsmokers\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\nfit$summary()\n\n# A tibble: 7 × 10\n  variable       mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n  <chr>         <num>  <num>  <num>  <num>  <num>  <num> <num>    <num>    <num>\n1 lp__         27.8   28.1   1.52   1.31   24.9   29.6    1.00    7997.    9743.\n2 tau_nonsmok… 22.6   21.9   6.68   6.53   12.9   34.5    1.00   17854.   12231.\n3 mu_nonsmoker  0.912  0.912 0.0449 0.0436  0.839  0.986  1.00   17455.   12780.\n4 tau_smoker    6.53   5.92  3.50   3.20    2.03  13.1    1.00   13257.   10335.\n5 mu_smoker     0.977  0.977 0.162  0.145   0.721  1.24   1.00   13512.    9947.\n6 testmu        0.667  1     0.471  0       0      1      1.00   16274.      NA \n7 r             4.83   3.72  4.27   2.19    1.43  11.7    1.00   14304.   11261.\n\n\nThese results are very similar to PyMC results."
  },
  {
    "objectID": "unit6/dugongs.html#problem-statement",
    "href": "unit6/dugongs.html#problem-statement",
    "title": "Dugongs",
    "section": "Problem Statement",
    "text": "Problem Statement\nCarlin and Gelfand (1991) investigated the age (x) and length (y) of 27 captured dugongs (sea cows). Estimate parameters in a nonlinear growth model.\n\nReferences\nData provided by Ratkowsky (1983).\nCarlin, B. and Gelfand, B. (1991). An Iterative Monte Carlo Method for Nonconjugate Bayesian Analysis, Statistics and Computing,\nRatkowsky, D. (1983). Nonlinear regression modeling: A unified practical approach. M. Dekker, NY, viii, 276 p.\n\n\nInput Data\n\nX <- c(1.0, 1.5, 1.5, 1.5, 2.5, 4.0, 5.0, 5.0, 7.0, 8.0, 8.5, 9.0, 9.5, \n     9.5, 10.0, 12.0, 12.0, 13.0, 13.0, 14.5, 15.5, 15.5, 16.5, 17.0,\n     22.5, 29.0, 31.5)\ny <- c(1.80, 1.85, 1.87, -1, 2.02, 2.27, 2.15, 2.26, 2.47, 2.19, 2.26,\n     2.40, 2.39, 2.41, 2.50, 2.32, 2.32, 2.43, 2.47, 2.56, 2.65, 2.47,\n     2.64, 2.56, 2.70, 2.72, -1)\n\nStan imputes missing values differently from PyMC and Bugs. We have to pass in the indices for the missing values as well as the count of observed and missing values.\n\nmod <- cmdstan_model(dugongs_stan)\n\nnow that we have compiled our stan file, we can print out the model that we will use for this:\n\nmod$print()\n\ndata {\n  int<lower=0> N_obs;\n  int<lower=0> N_mis;\n  array[N_obs] int<lower=1, upper=N_obs + N_mis> iy_obs;  // index of obs y's\n  array[N_mis] int<lower=1, upper=N_obs + N_mis> iy_mis;  // index of mis y's\n  vector[N_obs + N_mis] X;\n  vector[N_obs] y_obs;    // actual y values that were observed\n}\n\ntransformed data {\n  int<lower=0> N = N_obs + N_mis;  // total size of the input\n}\n\nparameters {\n  real alpha;\n  real beta;\n  real gamma;\n  real sigma;\n  vector[N_mis] y_mis;  // account for missing y\n}\n\ntransformed parameters {\n  vector[N] Y;         // Imputed Y values\n  Y[iy_obs] = y_obs;   // actual y values\n  Y[iy_mis] = y_mis;   // missing y values\n}\n\nmodel {\n  // priors\n  alpha ~ uniform(0, 100);\n  beta ~ uniform(0, 100);\n  gamma ~ uniform(0, 1);\n  sigma ~ uniform(-10, 10);\n  \n  Y ~ normal(alpha - beta * pow(gamma, X), sigma);\n}\n\n\n\n\nSampling\nLet us prepare the data to be passed into sample\n\n# Initial data has `-1` where missing.\nidx.mis <- which(y == -1)\nidx.obs <- which(y != -1)\n\ninput_data <- list(N_obs=length(idx.obs), N_mis=length(idx.mis),\n                  iy_obs=idx.obs, iy_mis=idx.mis,\n                  X=X,\n                  y_obs=y[idx.obs]\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\nfit$summary()\n\n# A tibble: 34 × 10\n   variable   mean  median     sd    mad      q5    q95  rhat ess_bulk ess_tail\n   <chr>     <num>   <num>  <num>  <num>   <num>  <num> <num>    <num>    <num>\n 1 lp__     49.5   49.9    2.09   1.90   45.5    52.2    1.00    5446.    7258.\n 2 alpha     2.73   2.71   0.125  0.106   2.57    2.96   1.00    3806.    2567.\n 3 beta      0.986  0.978  0.105  0.0925  0.833   1.16   1.00    5014.    2863.\n 4 gamma     0.886  0.891  0.0358 0.0313  0.823   0.936  1.00    4033.    3205.\n 5 sigma     0.100  0.0980 0.0165 0.0153  0.0771  0.130  1.00    8360.    8205.\n 6 y_mis[1]  1.91   1.91   0.114  0.111   1.72    2.09   1.00   11392.   11007.\n 7 y_mis[2]  2.69   2.69   0.128  0.123   2.48    2.90   1.00    6343.    6816.\n 8 Y[1]      1.8    1.8    0      0       1.8     1.8   NA         NA       NA \n 9 Y[2]      1.85   1.85   0      0       1.85    1.85  NA         NA       NA \n10 Y[3]      1.87   1.87   0      0       1.87    1.87  NA         NA       NA \n# ℹ 24 more rows\n\n\nThese results are very similar to PyMC results."
  },
  {
    "objectID": "unit6/equivalence.html#problem-statement",
    "href": "unit6/equivalence.html#problem-statement",
    "title": "Equivalence of Generic and Brand-name Drugs",
    "section": "Problem Statement",
    "text": "Problem Statement\nThe manufacturer wishes to demonstrate that their generic drug for a particular metabolic disorder is equivalent to a brand name drug. One of indication of the disorder is an abnormally low concentration of levocarnitine, an amino acid derivative, in the plasma. The treatment with the brand name drug substantially increases this concentration.\nA small clinical trial is conducted with 43 patients, 18 in the Brand Name Drug arm and 25 in the Generic Drug arm. The increases in the log-concentration of levocarnitine are in the data below.\nThe FDA declares that bioequivalence among the two drugs can be established if the difference in response to the two drugs is within 2 units of log-concentration. Assuming that the log-concentration measurements follow normal distributions with equal population variance, can these two drugs be declared bioequivalent within a tolerance +/-2 units?\n\n\nInput Data\nStarting with the data pasted from equivalence.odc.\n\nincrease.1 <- c(7, 8, 4, 6, 10, 10, 5, 7, 9, 8, 6, 7, 8, 4, 6, 10, 8, 9)\nincrease.2 <- c(6, 7, 5, 9, 5, 5, 3, 7, 5, 10, 8, 5, 8, 4, 4, 8, 6, 11, 7, 5, 5, 5, 7, 4, 6)\n\n\n\nHow do I track non-random variables in Stan?\nOne nice thing about BUGS is you can easily track both deterministic and non-deterministic variables while sampling. For Stan, you add the variable to the generated quantities block.\n\nmod <- cmdstan_model(equivalence_stan)\n\n\n\nStress, Diet, and Plasma Acids Model\n\n\ndata {\n  int<lower=0> N;\n  int<lower=0> M;\n  vector[N] y_type1;\n  vector[M] y_type2;\n}\n\nparameters {\n  real mu_type1;\n  real mu_type2;\n  real prec;\n}\n\ntransformed parameters {\n  real mudiff = mu_type1 - mu_type2;\n  real sigma = 1 / sqrt(prec);\n  real probint = ((mudiff + 2) >= 0 ? 1 : 0) * ((2 - mudiff) >= 0 ? 1 : 0);\n}\n\nmodel {\n  mu_type1 ~ normal(10, 1 / sqrt(1e-5));\n  mu_type2 ~ normal(10, 1 / sqrt(1e-5));\n  prec ~ gamma(0.001, 0.001);\n  \n  y_type1 ~ normal(mu_type1, sigma);\n  y_type2 ~ normal(mu_type2, sigma);\n}\n\n\n\n\nSampling\nLet us prepare the data to be passed into sample\n\ninput_data <- list(N=length(increase.1),\n                   M=length(increase.2),\n                   y_type1=increase.1,\n                   y_type2=increase.2\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\nfit$summary()\n\n# A tibble: 7 × 10\n  variable    mean  median     sd    mad      q5     q95  rhat ess_bulk ess_tail\n  <chr>      <num>   <num>  <num>  <num>   <num>   <num> <num>    <num>    <num>\n1 lp__     -49.4   -49.1   1.22   0.978  -51.8   -48.1    1.00    9921.   12770.\n2 mu_type1   7.33    7.34  0.467  0.461    6.57    8.09   1.00   16880.   13439.\n3 mu_type2   6.20    6.21  0.400  0.393    5.55    6.86   1.00   16065.   13287.\n4 prec       0.263   0.259 0.0581 0.0575   0.176   0.365  1.00   15209.   11437.\n5 mudiff     1.13    1.13  0.617  0.616    0.122   2.14   1.00   16797.   13707.\n6 sigma      1.99    1.96  0.226  0.218    1.66    2.39   1.00   15209.   11437.\n7 probint    0.922   1     0.268  0        0       1      1.00   14222.      NA \n\n\nThese results are very similar to PyMC results and BUGS results."
  },
  {
    "objectID": "unit6/psoriasis.html#problem-statement",
    "href": "unit6/psoriasis.html#problem-statement",
    "title": "Psoriasis: Two Sample Problem - paired data",
    "section": "Problem Statement",
    "text": "Problem Statement\nWoo and McKenna (2003) investigated the effect of broadband ultraviolet B (UVB) therapy and topical calcipotriol cream used together on areas of psoriasis. One of the outcome variables is the Psoriasis Area and Severity Index (PASI), where a lower score is better.\nThe PASI scores for 20 subjects are measured at baseline and after 8 treatments. Do these data provide sufficient evidence to indicate that the combination therapy reduces PASI scores?\nClassical Analysis:\nd = baseline - after;\nn = length(d);\ndbar = mean(d);   dbar = 6.3550\nsdd = sqrt(var(d)); sdd = 4.9309\ntstat = dbar / (sdd / sqrt(n));  tstat = 5.7637\n\nReject H_0 at the level alpha = 0.05 since the p_value = 0.00000744 < 0.05\n\n95% CI is [4.0472, 8.6628]\nSee Unit 6: Stress, Diet and Plasma Acids to find out more about recreating the BUGS step function.\n\nbaseline <- c(5.9, 7.6, 12.8, 16.5, 6.1, 14.4, 6.6, 5.4, 9.6, 11.6 ,11.1, 15.6, 9.6, 15.2, 21, 5.9, 10, 12.2, 20.2, 6.2)\nafter <- c(5.2, 12.2, 4.6, 4, 0.4 , 3.8, 1.2, 3.1, 3.5, 4.9, 11.1, 8.4, 5.8, 5, 6.4, 0, 2.7, 5.1, 4.8, 4.2)\n\n\nmod <- cmdstan_model(psoriasis_stan)\n\nWe do get a decent amount of warnings, but the model compiles and runs."
  },
  {
    "objectID": "unit6/psoriasis.html#model",
    "href": "unit6/psoriasis.html#model",
    "title": "Psoriasis: Two Sample Problem - paired data",
    "section": "Model",
    "text": "Model\n\n\n// Psoriasis: Two Sample Problem - Paired Data\ndata {\n  int<lower=0> N;\n  vector[N] baseline;\n  vector[N] after;\n}\n\ntransformed data {\n  vector[N] diff = baseline - after;\n}\n\nparameters {\n  real mu;\n  real prec;\n}\n\ntransformed parameters {\n  real sigma = 1 / sqrt(prec);\n  real ph1;\n  ph1 = (mu >= 0 ? 1 : 0);\n}\n\nmodel {\n  mu ~ normal(0, 316);\n  prec ~ gamma(0.001, 0.001);\n\n  diff ~ normal(mu, sigma);\n}\n\n\n\nSampling\nLet us prepare the data to be passed into sample\n\ninput_data <- list(N=length(baseline), \n                   baseline=baseline,\n                   after=after\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\nfit$summary()\n\n# A tibble: 5 × 10\n  variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n  <chr>       <num>    <num>  <num>  <num>    <num>    <num> <num>    <num>\n1 lp__     -39.2    -38.9    1.02   0.714  -41.2    -38.3     1.00    8495.\n2 mu         6.37     6.37   1.18   1.12     4.45     8.27    1.00    9440.\n3 prec       0.0411   0.0398 0.0133 0.0129   0.0218   0.0651  1.00    9661.\n4 sigma      5.14     5.01   0.893  0.814    3.92     6.78    1.00    9661.\n5 ph1        1        1      0      0        1        1      NA         NA \n# ℹ 1 more variable: ess_tail <num>\n\n\nThese results are very similar to BUGS and PyMC results."
  },
  {
    "objectID": "unit6/cheese.html#problem-statement",
    "href": "unit6/cheese.html#problem-statement",
    "title": "Taste of Cheese",
    "section": "Problem Statement",
    "text": "Problem Statement\nAs cheddar cheese matures, a variety of chemical processes take place. The taste of matured cheese is related to the concentration of several chemicals in the final product. In a study of cheddar cheese from the LaTrobe Valley of Victoria, Australia, samples of cheese were analyzed for their chemical composition and were subjected to taste tests. Overall taste scores were obtained by combining the scores from several tasters.\nCan the score be predicted well by the predictors: Acetic, H2S, and Lactic?\n\ndf <- read.csv(file.path('..', 'data', 'cheese.csv'), header = T, colClasses = c(\"NULL\", NA, NA, NA, NA))\n\n# This data list will be passed into the stan model\ndata_list <- list(\n  N = dim(df)[1],\n  acetic = df$Acetic,\n  h2s = df$H2S,\n  lactic = df$Lactic,\n  y = df$taste\n)\n\n\nModel\nWe will compile/build the stan model by running cmdstan_model. The cheese_program is the file path for the stan file, i.e. ../cheese.stan.\n\nmod <- cmdstan_model(cheese_stan)\n\nNow that we have compiled our stan file, we can print out the model:\n\nmod$print()\n\n// The data that is input into the model\ndata {\n  int<lower=0> N;\n  vector[N] acetic;\n  vector[N] h2s;\n  vector[N] lactic;\n  vector[N] y;\n}\n\nparameters {\n  real b0;               // Intercept coefficient\n  real b1;               // Slope coefficient\n  real b2;\n  real b3;\n  real tau;\n}\n\nmodel {\n  b0 ~ normal(0, 1 / sqrt(1e-5));\n  b1 ~ normal(0, 1 / sqrt(1e-5));\n  b2 ~ normal(0, 1 / sqrt(1e-5));\n  b3 ~ normal(0, 1 / sqrt(1e-5));\n  tau ~ gamma(0.001, 0.001);\n  \n  y ~ normal(b0 + b1 * acetic + b2 * h2s + b3 * lactic, 1 / sqrt(tau));\n}\n\ngenerated quantities {\n  array[N] real y_hat;\n  y_hat = normal_rng(b0 + b1 * acetic + b2 * h2s + b3 * lactic, 1 / sqrt(tau));\n}\n\n\n\n\nSampling\nNow that we have created the model above and compiled the stan program, we can start sampling.\n\nfit <- mod$sample(\n  data = data_list,\n  seed = 1,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000   # iterate 5,000 times\n)\n\n\nfit$summary(variables = c('b0', 'b1', 'b2', 'b3', 'tau'))\n\n# A tibble: 5 × 10\n  variable      mean    median       sd      mad       q5     q95  rhat ess_bulk\n  <chr>        <num>     <num>    <num>    <num>    <num>   <num> <num>    <num>\n1 b0       -28.6     -28.6     20.6     20.3     -6.26e+1  4.76    1.00    7508.\n2 b1         0.262     0.232    4.68     4.59    -7.32e+0  7.89    1.00    7056.\n3 b2         3.92      3.91     1.30     1.29     1.78e+0  6.04    1.00    8871.\n4 b3        19.7      19.6      9.02     8.70     4.87e+0 34.4     1.00    9316.\n5 tau        0.00973   0.00949  0.00270  0.00267  5.75e-3  0.0145  1.00   11940.\n# ℹ 1 more variable: ess_tail <num>\n\n\nThe results are pretty close to OpenBUGS.\n\n\nPredictions\nIn order to get the predictions, we will just need to pass in a new list of parameters with the predicted value\n\npred_data <- list(\n  N = 1,\n  acetic = 5.0,\n  h2s = 7.1,\n  lactic = 1.5,\n  y = 0 # We don't care what the value is for this because we are just trying to predict\n)\n\npred <- mod$generate_quantities(fitted_params = fit, data = pred_data)\n\n\nprint(pred)\n\n variable  mean median    sd   mad    q5   q95\n y_hat[1] 30.04  30.03 11.19 10.95 11.88 48.49"
  },
  {
    "objectID": "unit7/tas_mixture.html#problem-statement",
    "href": "unit7/tas_mixture.html#problem-statement",
    "title": "Priors as Hidden Mixtures",
    "section": "Problem Statement",
    "text": "Problem Statement\nWe are comparing the Student T likelihood with Normal prior vs Normal likelihood with Gamma prior.\n\nModel\n\nmod <- cmdstan_model(tas_mixture)\n\nnow that we have compiled our stan file, we can print out the model that we will use for this:\n\nmod$print()\n\ndata {\n  real df;\n  real mu0;\n  real tau1;\n  real tau;\n  real X;\n  real Y;\n}\n\nparameters {\n  real mu1;\n  real mu2;\n  real prec;\n}\n\ntransformed parameters {\n  real alpha = df / 2;\n  real beta = df / (2.0 * tau);\n}\n\nmodel {\n  mu1 ~ student_t(df, mu0, tau);\n  X ~ normal(mu1, 1 / sqrt(tau1));\n  \n  prec ~ gamma(alpha, beta);\n  mu2 ~ normal(mu0, 1 / sqrt(prec));\n  Y ~ normal(mu2, 1 / sqrt(tau1));\n}\n\n\n\n\nSampling\nWe don’t technically need to send anything in. We could add the values to the transformed data block. For this I decided to pass in the value. Therefore, let us prepare the data to be passed into sample\n\ninput_data <- list(\n  df = 6,\n  mu0 = 6,\n  tau1 = 10,\n  tau = 0.4,\n  X = 10,\n  Y = 10\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\nfit$summary()\n\n# A tibble: 6 × 10\n  variable    mean  median    sd   mad       q5     q95  rhat ess_bulk ess_tail\n  <chr>      <num>   <num> <num> <num>    <num>   <num> <num>    <num>    <num>\n1 lp__     -13.1   -12.8   1.26  1.02  -15.6    -11.8    1.00    7497.    9707.\n2 mu1        9.83    9.83  0.323 0.321   9.29    10.4    1.00   13632.   11613.\n3 mu2        9.91    9.91  0.315 0.309   9.40    10.4    1.00   13427.   11235.\n4 prec       0.234   0.211 0.126 0.115   0.0701   0.475  1.00    8902.    6831.\n5 alpha      3       3     0     0       3        3     NA         NA       NA \n6 beta       7.5     7.5   0     0       7.5      7.5   NA         NA       NA \n\n\nThese results are very similar to PyMC results."
  },
  {
    "objectID": "unit7/anovacoagulation.html#problem-statement",
    "href": "unit7/anovacoagulation.html#problem-statement",
    "title": "Coagulation",
    "section": "Problem Statement",
    "text": "Problem Statement\nHere 24 animals are randomly allocated to 4 different diets, but the numbers allocated to different diets are not the same. The coagulation time for blood is measured for each animal. Are the diet-based differences significant?\nBox, Hunter, Hunter; Statistics for Experimenters, p. 166\n\nModel\n\nmod <- cmdstan_model(anovacoagulation)\n\nAs you can see, this isn’t the best implementation of this. It currently requires typing each variable multiple times. This could have loops, which would reduce having to type out each variable multiple times.\n\nmod$print()\n\ndata {\n  int<lower=0> N1;\n  int<lower=0> N2;\n  int<lower=0> N3;\n  int<lower=0> N4;\n  vector[N1] y1;\n  vector[N2] y2;\n  vector[N3] y3;\n  vector[N4] y4;\n}\n\nparameters {\n  real mu0;\n  real<lower=0> tau;\n  \n  real alpha4;\n  real alpha3;\n  real alpha2;\n}\n\ntransformed parameters {\n  real alpha1 = -(alpha2 + alpha3 + alpha4);\n  real mu1 = mu0 + alpha1;\n  real mu2 = mu0 + alpha2;\n  real mu3 = mu0 + alpha3;\n  real mu4 = mu0 + alpha4;\n}\n\nmodel {\n  mu0 ~ normal(0, 1 / sqrt(0.0001));\n  tau ~ gamma(0.001, 0.001);\n  \n  alpha4 ~ normal(0, 1 / sqrt(0.0001));\n  alpha3 ~ normal(0, 1 / sqrt(0.0001));\n  alpha2 ~ normal(0, 1 / sqrt(0.0001));\n  \n  y1 ~ normal(mu1, 1 / sqrt(tau));\n  y2 ~ normal(mu2, 1 / sqrt(tau));\n  y3 ~ normal(mu3, 1 / sqrt(tau));\n  y4 ~ normal(mu4, 1 / sqrt(tau));\n}\n\ngenerated quantities {\n  real onetwo = alpha1 - alpha2;\n  real onethree = alpha1 - alpha3;\n  real onefour = alpha1 - alpha4;\n  real twothree = alpha2 - alpha3;\n  real twofour = alpha2 - alpha4;\n  real threefour = alpha3 - alpha4;\n}\n\n\n\n\nSampling\n\n# cut and pasted data from .odc file\ntimes = c(62, 60, 63, 59, 63, 67, 71, 64, 65, 66, 68, 66, 71, 67, 68, \n          68, 56, 62, 60, 61, 63, 64, 63, 59)\ndiets = c(1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, \n          3, 4, 4, 4, 4, 4, 4, 4, 4)\n\ny1 <- times[diets == 1]\ny2 <- times[diets == 2]\ny3 <- times[diets == 3]\ny4 <- times[diets == 4]\n\ninput_data <- list(\n  N1 = length(y1),\n  N2 = length(y2),\n  N3 = length(y3),\n  N4 = length(y4),\n  y1 = y1,\n  y2 = y2,\n  y3 = y3,\n  y4 = y4\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\n\nResults\nSince we don’t care about all the values, we are going to select the specific ones we care about.\n\nfit$summary(c(\"alpha4\", \"alpha3\", \"alpha2\", \"alpha1\", \"onetwo\", \"onethree\", \n              \"onefour\", \"twothree\", \"twofour\", \"threefour\"))\n\n# A tibble: 10 × 10\n   variable     mean  median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n   <chr>       <num>   <num> <num> <num>  <num>  <num> <num>    <num>    <num>\n 1 alpha4    -3.01   -3.01   0.822 0.799 -4.36  -1.67   1.00   19167.   14643.\n 2 alpha3     4.02    4.01   0.894 0.857  2.56   5.48   1.00   17767.   13792.\n 3 alpha2     1.99    2.00   0.884 0.856  0.529  3.43   1.00   19997.   14321.\n 4 alpha1    -3.00   -3.00   1.03  0.998 -4.69  -1.30   1.00   27457.   15674.\n 5 onetwo    -4.99   -5.00   1.61  1.54  -7.67  -2.33   1.00   25684.   15976.\n 6 onethree  -7.02   -7.00   1.62  1.58  -9.66  -4.37   1.00   23064.   15532.\n 7 onefour    0.0144  0.0129 1.54  1.49  -2.52   2.52   1.00   24007.   16103.\n 8 twothree  -2.03   -2.02   1.43  1.38  -4.41   0.311  1.00   17113.   12301.\n 9 twofour    5.01    5.01   1.34  1.30   2.80   7.23   1.00   18883.   13018.\n10 threefour  7.03    7.03   1.36  1.32   4.81   9.28   1.00   17591.   13736.\n\n\n\n\nPlot Intervals\nNow that we have the draws from the model, we can use them to plot intervals.\n\nfit$draws(variables = c(\"alpha4\", \"alpha3\", \"alpha2\", \"alpha1\")) |>\n  mcmc_intervals()\n\n\n\nfit$draws(variables = c(\"mu1\", \"mu2\", \"mu3\", \"mu4\", \"onetwo\", \"onethree\", \n                        \"onefour\", \"twothree\", \"twofour\", \"threefour\")) |>\n  mcmc_intervals()"
  }
]