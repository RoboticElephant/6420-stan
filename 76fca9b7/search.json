[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISYE 6420 - BUGS to Stan",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2\n\n\ninstall.packages(“cmdstanr”, repos = c(“https://mc-stan.org/r-packages/”, getOption(“repos”)))"
  },
  {
    "objectID": "about-class.html#other-recommended-resources",
    "href": "about-class.html#other-recommended-resources",
    "title": "About this course and website",
    "section": "Other recommended resources",
    "text": "Other recommended resources\nThese are not required for the class, but they might be helpful. Prof. Vidakovic’s lectures often assume that the student has a certain amount of background knowledge, so if you feel lost or if you just want to dive deeper into the subject check them out.\n\nTextbooks and courses\nStatistical Rethinking by Richard McElreath is a great book for gaining intuition about Bayesian inference and modeling in general.\n\nmain site\nlecture videos\nR and Stan code examples.\n\nBayesian Data Analysis by Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin goes into more mathematical theory than Statistical Rethinking. I use it as a reference - not planning to try reading this one all the way through!\n\nmain site\npdf\n\n\n\nBlogs\n\nAndrew Gelman, author of Bayesian Data Analysis (above), has a blog: Statistical Modeling, Causal Inference, and Social Science.\nDan Simpson, one of the maintainers of the Stan PPL, has a blog called Un garçon pas comme les autres (Bayes) with opinionated and funny deep dives into various Bayesian topics. Warning: NSFW language.\nCount Bayesie: Probably a probability blog by Will Kurt.\nMichael Betancourt, another Stan developer, has a series of incredibly in-depth posts and notebooks on Bayesian modeling.\nPyMC developer Austin Rochford’s blog has a lot of good posts.\nAnother PyMC developer, Oriol Abril, posts some really helpful PyMC examples.\n\n\n\nPodcasts\n\nLearn Bayes Stats by Alex Andorra, one of the PyMC developers.\n\n\n\nOther\n\nStan User’s Guide\nAaron Reding’s PyMC"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\ninstall.packages(\"rstan\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\ninstall.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "unit6/stress_diet.html#problem-statement",
    "href": "unit6/stress_diet.html#problem-statement",
    "title": "Stress, Diet, and Plasma Acids",
    "section": "Problem Statement",
    "text": "Problem Statement\nIn the study Interrelationships Between Stress, Dietary Intake, and Plasma Ascorbic Acid During Pregnancy conducted at the Virginia Polytechnic Institute and State University, the plasma ascorbic acid levels of pregnant women were compared for smokers versus non-smokers. Thirty-two women in the last three months of pregnancy, free of major health disorders, and ranging in age from 15 to 32 years were selected for the study. Prior to the collection of 20 ml of blood, the participants were told to avoid breakfast, forego their vitamin supplements, and avoid foods high in ascorbic acid content. From the blood samples, the plasma ascorbic acid values of each subject were determined in milligrams per 100 milliliters.\n\nI start with the data pasted from stressacids.odc, then create one list for smokers and one for nonsmokers.\n\nplasma <- c(0.97, 0.72, 1.00, 0.81, 0.62, 1.32, 1.24, 0.99, 0.90, 0.74,\n          0.88, 0.94, 1.06, 0.86, 0.85, 0.58, 0.57, 0.64, 0.98, 1.09,\n          0.92, 0.78, 1.24, 1.18, 0.48, 0.71, 0.98, 0.68, 1.18, 1.36,\n          0.78, 1.64)\n\nsmo <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2)\n\nnonsmoker_index <- which(smo == 1)\nplasma_smokers <- plasma[-nonsmoker_index]\nplasma_nonsmokers <- plasma[nonsmoker_index]\n\n\nBUGS step function\nBUGS defines the step function like this:\n\\[\nstep(e) = \\left\\{\n\\begin{array}{rl}\n  1, &\\; e \\geq 0\\\\\n  0, &\\; \\text{otherwise}\n\\end{array}\\right.\n\\]\nStan follows what you would expect in a programming language. We implement this like:\ne >= 0 ? 1 : 0;\n\n\nHow do I track non-random variables in Stan?\nOne nice thing about BUGS is you can easily track both deterministic and non-deterministic variables while sampling. For Stan, you add the variable to the generated quantities block.\n\nmod <- cmdstan_model(stress_diet_stan)\n\n\n\nStress, Diet, and Plasma Acids Model\n\n\ndata {\n  int<lower=0> N_smoker;\n  int<lower=0> N_nonsmoker;\n  vector[N_smoker] plasma_smoker;\n  vector[N_nonsmoker] plasma_nonsmoker;\n}\n\nparameters {\n  real<lower=0> tau_nonsmoker;\n  real mu_nonsmoker;\n  real<lower=0> tau_smoker;\n  real mu_smoker;\n}\n\nmodel {\n  tau_nonsmoker ~ gamma(0.0001, 0.0001);\n  tau_smoker ~ gamma(0.0001, 0.0001);\n  mu_nonsmoker ~ normal(0, 100); // equivalent to BUGS tau = 0.0001\n  mu_smoker ~ normal(0, 100);\n  \n  plasma_smoker ~ normal(mu_smoker, 1 / sqrt(tau_smoker));\n  plasma_nonsmoker ~ normal(mu_nonsmoker, 1 / sqrt(tau_nonsmoker));\n}\n\ngenerated quantities {\n  real testmu;\n  real r;\n  \n  testmu = (mu_smoker >= mu_nonsmoker ? 1 : 0);\n  r = tau_nonsmoker / tau_smoker;\n}\n\n\n\n\nSampling\nLet us prepare the data to be passed into sample\n\ninput_data <- list(N_smoker=length(plasma_smokers), \n                   N_nonsmoker=length(nonsmoker_index),\n                   plasma_smoker=plasma_smokers,\n                   plasma_nonsmoker=plasma_nonsmokers\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\nfit$summary()\n\n# A tibble: 7 × 10\n  variable       mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n  <chr>         <num>  <num>  <num>  <num>  <num>  <num> <num>    <num>    <num>\n1 lp__         27.8   28.1   1.52   1.31   24.9   29.6    1.00    7997.    9743.\n2 tau_nonsmok… 22.6   21.9   6.68   6.53   12.9   34.5    1.00   17854.   12231.\n3 mu_nonsmoker  0.912  0.912 0.0449 0.0436  0.839  0.986  1.00   17455.   12780.\n4 tau_smoker    6.53   5.92  3.50   3.20    2.03  13.1    1.00   13257.   10335.\n5 mu_smoker     0.977  0.977 0.162  0.145   0.721  1.24   1.00   13512.    9947.\n6 testmu        0.667  1     0.471  0       0      1      1.00   16274.      NA \n7 r             4.83   3.72  4.27   2.19    1.43  11.7    1.00   14304.   11261.\n\n\nThese results are very similar to PyMC results."
  },
  {
    "objectID": "unit6/dugongs.html#problem-statement",
    "href": "unit6/dugongs.html#problem-statement",
    "title": "Dugongs",
    "section": "Problem Statement",
    "text": "Problem Statement\nCarlin and Gelfand (1991) investigated the age (x) and length (y) of 27 captured dugongs (sea cows). Estimate parameters in a nonlinear growth model.\n\nReferences\nData provided by Ratkowsky (1983).\nCarlin, B. and Gelfand, B. (1991). An Iterative Monte Carlo Method for Nonconjugate Bayesian Analysis, Statistics and Computing,\nRatkowsky, D. (1983). Nonlinear regression modeling: A unified practical approach. M. Dekker, NY, viii, 276 p.\n\n\nInput Data\n\nX <- c(1.0, 1.5, 1.5, 1.5, 2.5, 4.0, 5.0, 5.0, 7.0, 8.0, 8.5, 9.0, 9.5, \n     9.5, 10.0, 12.0, 12.0, 13.0, 13.0, 14.5, 15.5, 15.5, 16.5, 17.0,\n     22.5, 29.0, 31.5)\ny <- c(1.80, 1.85, 1.87, -1, 2.02, 2.27, 2.15, 2.26, 2.47, 2.19, 2.26,\n     2.40, 2.39, 2.41, 2.50, 2.32, 2.32, 2.43, 2.47, 2.56, 2.65, 2.47,\n     2.64, 2.56, 2.70, 2.72, -1)\n\nStan imputes missing values differently from PyMC and Bugs. We have to pass in the indices for the missing values as well as the count of observed and missing values.\n\nmod <- cmdstan_model(dugongs_stan)\n\nnow that we have compiled our stan file, we can print out the model that we will use for this:\n\nmod$print()\n\ndata {\n  int<lower=0> N_obs;\n  int<lower=0> N_mis;\n  array[N_obs] int<lower=1, upper=N_obs + N_mis> iy_obs;  // index of obs y's\n  array[N_mis] int<lower=1, upper=N_obs + N_mis> iy_mis;  // index of mis y's\n  vector[N_obs + N_mis] X;\n  vector[N_obs] y_obs;    // actual y values that were observed\n}\n\ntransformed data {\n  int<lower=0> N = N_obs + N_mis;  // total size of the input\n}\n\nparameters {\n  real alpha;\n  real beta;\n  real gamma;\n  real sigma;\n  vector[N_mis] y_mis;  // account for missing y\n}\n\ntransformed parameters {\n  vector[N] Y;         // Imputed Y values\n  Y[iy_obs] = y_obs;   // actual y values\n  Y[iy_mis] = y_mis;   // missing y values\n}\n\nmodel {\n  // priors\n  alpha ~ uniform(0, 100);\n  beta ~ uniform(0, 100);\n  gamma ~ uniform(0, 1);\n  sigma ~ uniform(-10, 10);\n  \n  Y ~ normal(alpha - beta * pow(gamma, X), sigma);\n}\n\n\n\n\nSampling\nLet us prepare the data to be passed into sample\n\n# Initial data has `-1` where missing.\nidx.mis <- which(y == -1)\nidx.obs <- which(y != -1)\n\ninput_data <- list(N_obs=length(idx.obs), N_mis=length(idx.mis),\n                  iy_obs=idx.obs, iy_mis=idx.mis,\n                  X=X,\n                  y_obs=y[idx.obs]\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\nfit$summary()\n\n# A tibble: 34 × 10\n   variable   mean  median     sd    mad      q5    q95  rhat ess_bulk ess_tail\n   <chr>     <num>   <num>  <num>  <num>   <num>  <num> <num>    <num>    <num>\n 1 lp__     49.5   49.9    2.09   1.90   45.5    52.2    1.00    5446.    7258.\n 2 alpha     2.73   2.71   0.125  0.106   2.57    2.96   1.00    3806.    2567.\n 3 beta      0.986  0.978  0.105  0.0925  0.833   1.16   1.00    5014.    2863.\n 4 gamma     0.886  0.891  0.0358 0.0313  0.823   0.936  1.00    4033.    3205.\n 5 sigma     0.100  0.0980 0.0165 0.0153  0.0771  0.130  1.00    8360.    8205.\n 6 y_mis[1]  1.91   1.91   0.114  0.111   1.72    2.09   1.00   11392.   11007.\n 7 y_mis[2]  2.69   2.69   0.128  0.123   2.48    2.90   1.00    6343.    6816.\n 8 Y[1]      1.8    1.8    0      0       1.8     1.8   NA         NA       NA \n 9 Y[2]      1.85   1.85   0      0       1.85    1.85  NA         NA       NA \n10 Y[3]      1.87   1.87   0      0       1.87    1.87  NA         NA       NA \n# ℹ 24 more rows\n\n\nThese results are very similar to PyMC results."
  },
  {
    "objectID": "unit6/equivalence.html#problem-statement",
    "href": "unit6/equivalence.html#problem-statement",
    "title": "Equivalence of Generic and Brand-name Drugs",
    "section": "Problem Statement",
    "text": "Problem Statement\nThe manufacturer wishes to demonstrate that their generic drug for a particular metabolic disorder is equivalent to a brand name drug. One of indication of the disorder is an abnormally low concentration of levocarnitine, an amino acid derivative, in the plasma. The treatment with the brand name drug substantially increases this concentration.\nA small clinical trial is conducted with 43 patients, 18 in the Brand Name Drug arm and 25 in the Generic Drug arm. The increases in the log-concentration of levocarnitine are in the data below.\nThe FDA declares that bioequivalence among the two drugs can be established if the difference in response to the two drugs is within 2 units of log-concentration. Assuming that the log-concentration measurements follow normal distributions with equal population variance, can these two drugs be declared bioequivalent within a tolerance +/-2 units?\n\n\nInput Data\nStarting with the data pasted from equivalence.odc.\n\nincrease.1 <- c(7, 8, 4, 6, 10, 10, 5, 7, 9, 8, 6, 7, 8, 4, 6, 10, 8, 9)\nincrease.2 <- c(6, 7, 5, 9, 5, 5, 3, 7, 5, 10, 8, 5, 8, 4, 4, 8, 6, 11, 7, 5, 5, 5, 7, 4, 6)\n\n\n\nHow do I track non-random variables in Stan?\nOne nice thing about BUGS is you can easily track both deterministic and non-deterministic variables while sampling. For Stan, you add the variable to the generated quantities block.\n\nmod <- cmdstan_model(equivalence_stan)\n\n\n\nStress, Diet, and Plasma Acids Model\n\n\ndata {\n  int<lower=0> N;\n  int<lower=0> M;\n  vector[N] y_type1;\n  vector[M] y_type2;\n}\n\nparameters {\n  real mu_type1;\n  real mu_type2;\n  real prec;\n}\n\ntransformed parameters {\n  real mudiff = mu_type1 - mu_type2;\n  real sigma = 1 / sqrt(prec);\n  real probint = ((mudiff + 2) >= 0 ? 1 : 0) * ((2 - mudiff) >= 0 ? 1 : 0);\n}\n\nmodel {\n  mu_type1 ~ normal(10, 1 / sqrt(1e-5));\n  mu_type2 ~ normal(10, 1 / sqrt(1e-5));\n  prec ~ gamma(0.001, 0.001);\n  \n  y_type1 ~ normal(mu_type1, sigma);\n  y_type2 ~ normal(mu_type2, sigma);\n}\n\n\n\n\nSampling\nLet us prepare the data to be passed into sample\n\ninput_data <- list(N=length(increase.1),\n                   M=length(increase.2),\n                   y_type1=increase.1,\n                   y_type2=increase.2\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\nfit$summary()\n\n# A tibble: 7 × 10\n  variable    mean  median     sd    mad      q5     q95  rhat ess_bulk ess_tail\n  <chr>      <num>   <num>  <num>  <num>   <num>   <num> <num>    <num>    <num>\n1 lp__     -49.4   -49.1   1.22   0.978  -51.8   -48.1    1.00    9921.   12770.\n2 mu_type1   7.33    7.34  0.467  0.461    6.57    8.09   1.00   16880.   13439.\n3 mu_type2   6.20    6.21  0.400  0.393    5.55    6.86   1.00   16065.   13287.\n4 prec       0.263   0.259 0.0581 0.0575   0.176   0.365  1.00   15209.   11437.\n5 mudiff     1.13    1.13  0.617  0.616    0.122   2.14   1.00   16797.   13707.\n6 sigma      1.99    1.96  0.226  0.218    1.66    2.39   1.00   15209.   11437.\n7 probint    0.922   1     0.268  0        0       1      1.00   14222.      NA \n\n\nThese results are very similar to PyMC results and BUGS results."
  },
  {
    "objectID": "unit6/psoriasis.html#problem-statement",
    "href": "unit6/psoriasis.html#problem-statement",
    "title": "Psoriasis: Two Sample Problem - paired data",
    "section": "Problem Statement",
    "text": "Problem Statement\nWoo and McKenna (2003) investigated the effect of broadband ultraviolet B (UVB) therapy and topical calcipotriol cream used together on areas of psoriasis. One of the outcome variables is the Psoriasis Area and Severity Index (PASI), where a lower score is better.\nThe PASI scores for 20 subjects are measured at baseline and after 8 treatments. Do these data provide sufficient evidence to indicate that the combination therapy reduces PASI scores?\nClassical Analysis:\nd = baseline - after;\nn = length(d);\ndbar = mean(d);   dbar = 6.3550\nsdd = sqrt(var(d)); sdd = 4.9309\ntstat = dbar / (sdd / sqrt(n));  tstat = 5.7637\n\nReject H_0 at the level alpha = 0.05 since the p_value = 0.00000744 < 0.05\n\n95% CI is [4.0472, 8.6628]\nSee Unit 6: Stress, Diet and Plasma Acids to find out more about recreating the BUGS step function.\n\nbaseline <- c(5.9, 7.6, 12.8, 16.5, 6.1, 14.4, 6.6, 5.4, 9.6, 11.6 ,11.1, 15.6, 9.6, 15.2, 21, 5.9, 10, 12.2, 20.2, 6.2)\nafter <- c(5.2, 12.2, 4.6, 4, 0.4 , 3.8, 1.2, 3.1, 3.5, 4.9, 11.1, 8.4, 5.8, 5, 6.4, 0, 2.7, 5.1, 4.8, 4.2)\n\n\nmod <- cmdstan_model(psoriasis_stan)\n\nWe do get a decent amount of warnings, but the model compiles and runs."
  },
  {
    "objectID": "unit6/psoriasis.html#model",
    "href": "unit6/psoriasis.html#model",
    "title": "Psoriasis: Two Sample Problem - paired data",
    "section": "Model",
    "text": "Model\n\n\n// Psoriasis: Two Sample Problem - Paired Data\ndata {\n  int<lower=0> N;\n  vector[N] baseline;\n  vector[N] after;\n}\n\ntransformed data {\n  vector[N] diff = baseline - after;\n}\n\nparameters {\n  real mu;\n  real prec;\n}\n\ntransformed parameters {\n  real sigma = 1 / sqrt(prec);\n  real ph1;\n  ph1 = (mu >= 0 ? 1 : 0);\n}\n\nmodel {\n  mu ~ normal(0, 316);\n  prec ~ gamma(0.001, 0.001);\n\n  diff ~ normal(mu, sigma);\n}\n\n\n\nSampling\nLet us prepare the data to be passed into sample\n\ninput_data <- list(N=length(baseline), \n                   baseline=baseline,\n                   after=after\n)\n\nNow that we have the data to pass into our sampling, let’s proceed.\n\nfit <- mod$sample(\n  data = input_data,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000\n)\n\n\nfit$summary()\n\n# A tibble: 5 × 10\n  variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n  <chr>       <num>    <num>  <num>  <num>    <num>    <num> <num>    <num>\n1 lp__     -39.2    -38.9    1.02   0.714  -41.2    -38.3     1.00    8495.\n2 mu         6.37     6.37   1.18   1.12     4.45     8.27    1.00    9440.\n3 prec       0.0411   0.0398 0.0133 0.0129   0.0218   0.0651  1.00    9661.\n4 sigma      5.14     5.01   0.893  0.814    3.92     6.78    1.00    9661.\n5 ph1        1        1      0      0        1        1      NA         NA \n# ℹ 1 more variable: ess_tail <num>\n\n\nThese results are very similar to BUGS and PyMC results."
  },
  {
    "objectID": "unit6/cheese.html#problem-statement",
    "href": "unit6/cheese.html#problem-statement",
    "title": "Taste of Cheese",
    "section": "Problem Statement",
    "text": "Problem Statement\nAs cheddar cheese matures, a variety of chemical processes take place. The taste of matured cheese is related to the concentration of several chemicals in the final product. In a study of cheddar cheese from the LaTrobe Valley of Victoria, Australia, samples of cheese were analyzed for their chemical composition and were subjected to taste tests. Overall taste scores were obtained by combining the scores from several tasters.\nCan the score be predicted well by the predictors: Acetic, H2S, and Lactic?\n\ndf <- read.csv(file.path('..', 'data', 'cheese.csv'), header = T, colClasses = c(\"NULL\", NA, NA, NA, NA))\n\n# This data list will be passed into the stan model\ndata_list <- list(\n  N = dim(df)[1],\n  acetic = df$Acetic,\n  h2s = df$H2S,\n  lactic = df$Lactic,\n  y = df$taste\n)\n\n\nModel\nWe will compile/build the stan model by running cmdstan_model. The cheese_program is the file path for the stan file, i.e. ../cheese.stan.\n\nmod <- cmdstan_model(cheese_stan)\n\nNow that we have compiled our stan file, we can print out the model:\n\nmod$print()\n\n// The data that is input into the model\ndata {\n  int<lower=0> N;\n  vector[N] acetic;\n  vector[N] h2s;\n  vector[N] lactic;\n  vector[N] y;\n}\n\nparameters {\n  real b0;               // Intercept coefficient\n  real b1;               // Slope coefficient\n  real b2;\n  real b3;\n  real tau;\n}\n\nmodel {\n  b0 ~ normal(0, 1 / sqrt(1e-5));\n  b1 ~ normal(0, 1 / sqrt(1e-5));\n  b2 ~ normal(0, 1 / sqrt(1e-5));\n  b3 ~ normal(0, 1 / sqrt(1e-5));\n  tau ~ gamma(0.001, 0.001);\n  \n  y ~ normal(b0 + b1 * acetic + b2 * h2s + b3 * lactic, 1 / sqrt(tau));\n}\n\ngenerated quantities {\n  array[N] real y_hat;\n  y_hat = normal_rng(b0 + b1 * acetic + b2 * h2s + b3 * lactic, 1 / sqrt(tau));\n}\n\n\n\n\nSampling\nNow that we have created the model above and compiled the stan program, we can start sampling.\n\nfit <- mod$sample(\n  data = data_list,\n  seed = 1,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 500,   # print update every 500 iterations\n  iter_warmup = 1000,\n  iter_sampling = 5000   # iterate 5,000 times\n)\n\n\nfit$summary(variables = c('b0', 'b1', 'b2', 'b3', 'tau'))\n\n# A tibble: 5 × 10\n  variable      mean    median       sd      mad       q5     q95  rhat ess_bulk\n  <chr>        <num>     <num>    <num>    <num>    <num>   <num> <num>    <num>\n1 b0       -28.6     -28.6     20.6     20.3     -6.26e+1  4.76    1.00    7508.\n2 b1         0.262     0.232    4.68     4.59    -7.32e+0  7.89    1.00    7056.\n3 b2         3.92      3.91     1.30     1.29     1.78e+0  6.04    1.00    8871.\n4 b3        19.7      19.6      9.02     8.70     4.87e+0 34.4     1.00    9316.\n5 tau        0.00973   0.00949  0.00270  0.00267  5.75e-3  0.0145  1.00   11940.\n# ℹ 1 more variable: ess_tail <num>\n\n\nThe results are pretty close to OpenBUGS.\n\n\nPredictions\nIn order to get the predictions, we will just need to pass in a new list of parameters with the predicted value\n\npred_data <- list(\n  N = 1,\n  acetic = 5.0,\n  h2s = 7.1,\n  lactic = 1.5,\n  y = 0 # We don't care what the value is for this because we are just trying to predict\n)\n\npred <- mod$generate_quantities(fitted_params = fit, data = pred_data)\n\n\nprint(pred)\n\n variable  mean median    sd   mad    q5   q95\n y_hat[1] 30.19  30.27 11.36 11.03 11.75 48.54"
  }
]